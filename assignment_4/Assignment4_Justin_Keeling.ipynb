{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment4_FNAME_LNAME",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flwL8jnTalH2",
        "colab_type": "text"
      },
      "source": [
        "# Assignment 4 - Information Retrieval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNl9RkYUaMpd",
        "colab_type": "text"
      },
      "source": [
        "In this assignment, you will implement code for information retrieval."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFTHMIH2abrJ",
        "colab_type": "text"
      },
      "source": [
        "## Part 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiuFMWIVatYM",
        "colab_type": "text"
      },
      "source": [
        "For this part, you will be learning to use sklearn's in-buit functionality to find the most relevant (toy) document for a given query. You will use the [TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) for computing tfidf scores. Then you will use the [cosine_similarity](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_similarity.html) to compute the similarity between a given query and the documents."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gR286kAc6XY3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H81Xv1aB5mnk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define the toy documets and the query\n",
        "Doc1 = 'Information Retrieval Systems'\n",
        "Doc2 = 'Information Storage'\n",
        "Doc3 = 'Digital Speech Synthesis Systems'\n",
        "Doc4 = 'Speech Filtering, Speech Retrieval'\n",
        "docs = [Doc1, Doc2, Doc3, Doc4]\n",
        "\n",
        "query = ['Speech Systems']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-TMlXY-5gZ9",
        "colab_type": "code",
        "outputId": "5817f36a-642b-4704-a4b0-a8f6f8803a2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# create the vectorizer\n",
        "vectorizer = TfidfVectorizer() \n",
        "# fit and transform the documents\n",
        "documents_v = vectorizer.fit_transform(docs)\n",
        "# prepare the query using the same vectorizer\n",
        "query_v = vectorizer.transform(query)\n",
        "# calculate cosine similarity score for each document with respect to the query\n",
        "print(cosine_similarity(query_v, documents_v))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.40824829 0.         0.6191303  0.55011649]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJh_MRV3Dm3X",
        "colab_type": "text"
      },
      "source": [
        "# Part 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epJKfQWSD6UM",
        "colab_type": "text"
      },
      "source": [
        "CACM is a collection of abstracts of articles published in the Communications of the ACM journal between 1958 and 1979. This collection has been used in numerous papers for the evaluation of information retrieval systems. The entire collection (3024 documents) is provided and is comprised of 3 files:\n",
        "* cacm.tar.gz contains the 3024 html files.\n",
        "* cacm.query contains the 64 queries.\n",
        "* cacm.rel contains the relevance query results for each of the 64 queries.\n",
        "\n",
        "Write code that eliminates all HTML tags and then tokenizes the text. Ignore the numeric columns at the end of each file. Use the tokenized text to answer the following questions.\n",
        "\n",
        "Relevant functionality in *NLTK*: functions *nltk.clean_html*, *word_tokenize* and *sent_tokenize* from package *nltk.tokenize*.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jY1l3SewFAKg",
        "colab_type": "text"
      },
      "source": [
        "1. How many tokens are in the entire collection?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2uZG25xFlwg",
        "colab_type": "text"
      },
      "source": [
        "2. What is the size of the vocabulary?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPkM_-AVFp3x",
        "colab_type": "text"
      },
      "source": [
        "3. How many vocabulary entries are mentioned only once in the entire collection? How about two times?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvZELkrJFrdW",
        "colab_type": "text"
      },
      "source": [
        "4. What are the top 20 most common token types?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejZnRKHiFvDM",
        "colab_type": "text"
      },
      "source": [
        "5. What is the percentage of tokens in the collection that is covered by these 20 most common token types?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGrM8_mXGsTY",
        "colab_type": "text"
      },
      "source": [
        "Further, process the text by lower casing and eliminating stopwords. Do stemming using Porterâ€™s algorithm. Use the  fully preprocessed (tokenization, stemming, stopwords removal, and case folding) version of the text to answer the same five questions from above.\n",
        "\n",
        "Relevant functionality in *NLTK*: class *PorterStemmer* from package *nltk.stem.porter*; the stopwords corpus from package *nltk.corpus*)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0viWsWmDIbeQ"
      },
      "source": [
        "1. How many tokens are in the entire collection?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rpRW32pYIbeS"
      },
      "source": [
        "2. What is the size of the vocabulary?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WqmvDic4IbeT"
      },
      "source": [
        "3. How many vocabulary entries are mentioned only once in the entire collection? How about two times?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oP2FQFTPIbeU"
      },
      "source": [
        "4. What are the top 20 most common token types?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zj0BDGsKIbeV"
      },
      "source": [
        "5. What is the percentage of tokens in the collection that is covered by these 20 most common token types?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_SxaRP1In72",
        "colab_type": "text"
      },
      "source": [
        "Now Compute and report the Mean Average Precision (MAP) for all 64 queries in CACM. You may follow these steps.\n",
        "1. Vectorize the entire collection using *TfidfVectorizer* as above.\n",
        "2. Vectorize query *i* (see *cacm.query* file)\n",
        "3. Compute cosine similarity between query *i* and the collection.\n",
        "4. Rank the collection for query *i* using the above scores.\n",
        "5. Compute Average Precision (AP) for query *i* as discussed in the class (*cacm.rel* file provides the relevances. Ignore the 2nd column).\n",
        "6. Macro-average APs across all queries to compute the MAP.  \n",
        "\n",
        "To maximize the performance of your model, explore all the parameters of *TfidfVectorizer*. List the combination of parameter values that provided best MAP for you. Describe anything else you may have tried (and has helped you to acheive your best performance). \n",
        "\n",
        "The three best reported MAP values will get **bonus points** (5% of the assignment grade for the 1st place, 3% for 2nd, and 2% for 3rd). The winner will be announced in the class after final evaluation.\n",
        "\n",
        "(Note: merely 'reporting' the MAP is not enough. You should have the entire code to generate the best MAP so that the grader can compute the MAP while grading.)\n",
        "\n"
      ]
    }
  ]
}